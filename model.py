import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import os


class Chomp1d(nn.Module):
    def __init__(self, chomp_size):
        super().__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        return x[:, :, :-self.chomp_size].contiguous()


class TemporalBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout=0.2):
        super().__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)
        self.chomp1 = Chomp1d(padding)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.leaky_relu1 = nn.LeakyReLU(0.1)
        self.drop1 = nn.Dropout(dropout)
        
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation)
        self.chomp2 = Chomp1d(padding)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.leaky_relu2 = nn.LeakyReLU(0.1)
        self.drop2 = nn.Dropout(dropout)

        self.net = nn.Sequential(
            self.conv1, self.chomp1, self.bn1, self.leaky_relu1, self.drop1,
            self.conv2, self.chomp2, self.bn2, self.leaky_relu2, self.drop2
        )

        self.downsample = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, 1),
            nn.BatchNorm1d(out_channels)
        ) if in_channels != out_channels else None
        
        self.final_activation = nn.LeakyReLU(0.1)

    def forward(self, x):
        """
        TemporalBlockì˜ ìˆœì „íŒŒ í•¨ìˆ˜.
        
        Args:
            x: ì…ë ¥ í…ì„œ, í˜•íƒœ: (batch_size, in_channels, seq_len)
            
        Returns:
            ì¶œë ¥ í…ì„œ, í˜•íƒœ: (batch_size, out_channels, seq_len)
        """
        out = self.net(x)
        res = x if self.downsample is None else self.downsample(x)
        return self.final_activation(out + res)


class TCNEncoder(nn.Module):
    def __init__(self, input_size, hidden_size, num_channels, kernel_size=3, dropout=0.2):
        super().__init__()
        layers = []
        for i, ch in enumerate(num_channels):
            dilation = 2 ** i
            in_ch = input_size if i == 0 else num_channels[i-1]
            pad = (kernel_size - 1) * dilation
            layers.append(TemporalBlock(in_ch, ch, kernel_size, stride=1, 
                dilation=dilation, padding=pad, dropout=dropout))
        
        self.network = nn.Sequential(*layers)
        
        self.output_projection = nn.Sequential(
            nn.Linear(num_channels[-1], hidden_size),
            nn.LeakyReLU(0.1)
        )
        
    def forward(self, x):
        """
        TCNEncoderì˜ ìˆœì „íŒŒ í•¨ìˆ˜.
        
        Args:
            x: ì…ë ¥ í…ì„œ, í˜•íƒœ: (batch_size, seq_len, input_size)
            Conv1dë¥¼ ìœ„í•´ (batch_size, input_size, seq_len)ë¡œ ë³€í™˜ë¨
        
        Returns:
            ì¶œë ¥ í…ì„œ, í˜•íƒœ: (batch_size, hidden_size)
            ì „ì²´ ì‹œí€€ìŠ¤ë¥¼ ì¸ì½”ë”©í•˜ëŠ” ìµœì¢… ì€ë‹‰ ìƒíƒœë¥¼ ë‚˜íƒ€ëƒ„
        """
        # Conv1dë¥¼ ìœ„í•œ ì „ì¹˜: (batch, seq, features) â†’ (batch, features, seq)
        x = x.transpose(1, 2)
        
        # TCN ë ˆì´ì–´ë“¤ì„ í†µê³¼
        out = self.network(x)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì„ íƒ: (batch, channels, seq) â†’ (batch, channels)
        out = out[:, :, -1]
        
        # ìµœì¢… ì€ë‹‰ í¬ê¸°ë¡œ íˆ¬ì˜
        out = self.output_projection(out)
        return out


class BetaEstimator(nn.Module):
    def __init__(self, num_assets=5, hidden_size=64, num_channels=[32, 64, 128], kernel_size=3, dropout=0.2):
        super().__init__()
        self.num_assets = num_assets
        self.returns_encoder = TCNEncoder(
            input_size=1,
            hidden_size=hidden_size,
            num_channels=num_channels,
            kernel_size=kernel_size,
            dropout=dropout
        )
        self.asset_embeddings = nn.Embedding(num_assets, hidden_size)
        self.beta_predictor = nn.Sequential(
            nn.Linear(hidden_size * 3, hidden_size),
            nn.BatchNorm1d(hidden_size),
            nn.LeakyReLU(0.1),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, 1)
        )       

    def forward(self, asset_data, common_data):
        """
        ë²¡í„°í™”ëœ ì—°ì‚°ì„ ì‚¬ìš©í•œ ìµœì í™”ëœ ìˆœì „íŒŒ í•¨ìˆ˜.
        
        Args:
            asset_data: ìì‚° ìˆ˜ìµë¥  í…ì„œ
                - ë°°ì¹˜ ì²˜ë¦¬ ì‹œ: (batch_size, num_assets, seq_len, 1)
                - ë‹¨ì¼ ìƒ˜í”Œ: (num_assets, seq_len, 1)
            common_data: ê³µí†µ ì‹œì¥ ë°ì´í„°
                - ë°°ì¹˜ ì²˜ë¦¬ ì‹œ: (batch_size, seq_len, num_features)
                - ë‹¨ì¼ ìƒ˜í”Œ: (seq_len, num_features)
                        
        Returns:
            betas: ì˜ˆì¸¡ëœ ë² íƒ€ ê³„ìˆ˜, í˜•íƒœ: (batch_size, num_assets)
        """
        # ë°ì´í„°ë¡œë”ì—ì„œ ì˜¤ëŠ” í˜•íƒœì— ë§ê²Œ ì°¨ì› ì¡°ì •
        if asset_data.dim() == 4:
            # ë°°ì¹˜ ì²˜ë¦¬: (batch_size, num_assets, seq_len, 1) -> (batch_size, num_assets, seq_len)
            asset_data = asset_data.squeeze(-1)
        elif asset_data.dim() == 3 and asset_data.shape[2] == 1:
            # ë‹¨ì¼ ìƒ˜í”Œ: (num_assets, seq_len, 1) -> (1, num_assets, seq_len)
            asset_data = asset_data.squeeze(-1).unsqueeze(0)
        
        if common_data.dim() == 2:
            # ë‹¨ì¼ ìƒ˜í”Œ: (seq_len, num_features) -> (1, seq_len, num_features)
            common_data = common_data.unsqueeze(0)
        # ë°°ì¹˜ ì²˜ë¦¬ì¸ ê²½ìš° (batch_size, seq_len, num_features)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
            
        batch_size, num_assets, seq_len = asset_data.shape
        device = asset_data.device
        
        # ì‹œì¥ ìˆ˜ìµë¥  ì¶”ì¶œ ë° ì¸ì½”ë”© (ê¸°ì¡´ê³¼ ë™ì¼)
        market_returns = common_data[:, :, 0].unsqueeze(-1)  # (batch, seq_len, 1)
        market_context = self.returns_encoder(market_returns)  # (batch, hidden_size)
        
        # ğŸ”¥ í•µì‹¬ ìµœì í™”: ëª¨ë“  ìì‚°ì„ í•œ ë²ˆì— ì²˜ë¦¬
        # ë‹¨ê³„ 1: ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìì‚° ë°ì´í„° ì¬êµ¬ì„±
        asset_returns_flat = asset_data.transpose(1, 2).reshape(-1, seq_len).unsqueeze(-1)
        # ë³€í™˜: (batch, assets, seq) â†’ (batch, seq, assets) â†’ (batch*assets, seq) â†’ (batch*assets, seq, 1)
        
        # ë‹¨ê³„ 2: ë‹¨ì¼ TCN í˜¸ì¶œë¡œ ëª¨ë“  ìì‚° ì²˜ë¦¬
        asset_contexts_flat = self.returns_encoder(asset_returns_flat)  # (batch*assets, hidden_size)
        
        # ë‹¨ê³„ 3: ê°œë³„ ìì‚°ìœ¼ë¡œ ë‹¤ì‹œ ì¬êµ¬ì„±
        asset_contexts = asset_contexts_flat.view(batch_size, num_assets, -1)  # (batch, assets, hidden_size)
        
        # ë‹¨ê³„ 4: ëª¨ë“  ìì‚°ì— ëŒ€í•œ ìì‚° ì„ë² ë”© í•œ ë²ˆì— ìƒì„±
        asset_ids = torch.arange(num_assets, device=device).unsqueeze(0).expand(batch_size, -1)
        asset_embeddings = self.asset_embeddings(asset_ids)  # (batch, assets, hidden_size)
        
        # ë‹¨ê³„ 5: ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìì‚° ì°¨ì›ì— ë§ê²Œ í™•ì¥
        market_context_expanded = market_context.unsqueeze(1).expand(-1, num_assets, -1)
        
        # ë‹¨ê³„ 6: ëª¨ë“  ì •ë³´ ì†ŒìŠ¤ ê²°í•©
        combined = torch.cat([
            asset_contexts,           # (batch, assets, hidden_size)
            market_context_expanded,  # (batch, assets, hidden_size)
            asset_embeddings         # (batch, assets, hidden_size)
        ], dim=2)  # (batch, assets, hidden_size * 3)
        
        # ë‹¨ê³„ 7: MLP ì²˜ë¦¬ë¥¼ ìœ„í•œ í‰íƒ„í™” ë° ëª¨ë“  ë² íƒ€ í•œ ë²ˆì— ì˜ˆì¸¡
        combined_flat = combined.view(-1, combined.size(-1))  # (batch*assets, hidden_size*3)
        betas_flat = self.beta_predictor(combined_flat)  # (batch*assets, 1)
        
        # ë‹¨ê³„ 8: ìµœì¢… í˜•íƒœë¡œ ì¬êµ¬ì„±
        betas = betas_flat.view(batch_size, num_assets)  # (batch, assets)
        
        return betas


class AdaptivePortfolioOptimizer(nn.Module):
    """
    TCN ê¸°ë°˜ ë² íƒ€ ì¶”ì •ì„ ì‚¬ìš©í•œ ì ì‘í˜• í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
    
    ì‘ì—… íë¦„:
    1. TCNì´ ê° ìì‚°ì˜ ë² íƒ€ë¥¼ ì¶”ì •
    2. CAPMìœ¼ë¡œ ë² íƒ€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ëŒ€ ìˆ˜ìµë¥  ê³„ì‚°
    3. ë°°ì¹˜ ë°ì´í„°ì—ì„œ ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
    4. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ í‰ê· -ë¶„ì‚° ìµœì í™”
    5. ëª©ì  í•¨ìˆ˜ë¡œ ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
    6. ìµœëŒ€í™”ë¥¼ ìœ„í•œ ì†ì‹¤ë¡œ ìŒì˜ ìƒ¤í”„ ë¹„ìœ¨ ì‚¬ìš©
    """
    
    def __init__(self, num_assets=5, hidden_size=64, num_channels=[32, 64, 128], kernel_size=3, dropout=0.2, risk_free_rate=0.02):
        super().__init__()
        
        self.num_assets = num_assets
        
        # ë² íƒ€ ì¶”ì • ëª¨ë“ˆ
        self.beta_estimator = BetaEstimator(
            num_assets=num_assets,
            hidden_size=hidden_size,
            num_channels=num_channels,
            kernel_size=kernel_size,
            dropout=dropout
        )
        
        # ì–‘ì˜ ì •ë¶€í˜¸ ê³µë¶„ì‚°ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ì •ê·œí™” í•­ (ì•ˆì •ì„±ì„ ìœ„í•´ ì¦ê°€)
        self.cov_regularization = 1e-4
    
    def capm_expected_returns(self, betas, market_return, risk_free_rate=None, common_data=None):
        """
        CAPMì„ ì‚¬ìš©í•œ ê¸°ëŒ€ ìˆ˜ìµë¥  ê³„ì‚°: E(R_i) = R_f + Î²_i * (E(R_m) - R_f)
        
        Args:
            betas: ìì‚° ë² íƒ€ (batch_size, num_assets)
            market_return: ì‹œì¥ ìˆ˜ìµë¥  (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - common_dataì˜ Mkt-RF ì§ì ‘ ì‚¬ìš©)
            risk_free_rate: ë¬´ìœ„í—˜ ì´ììœ¨ (ìŠ¤ì¹¼ë¼), Noneì´ë©´ common_dataì—ì„œ ì¶”ì¶œ
            common_data: ê³µí†µ ì‹œì¥ ë°ì´í„° (batch_size, seq_len, num_features)
                        - ì¸ë±ìŠ¤ 0: Mkt-RF (ì‹œì¥ ìœ„í—˜ í”„ë¦¬ë¯¸ì—„) â† ì§ì ‘ ì‚¬ìš©
                        - ì¸ë±ìŠ¤ 1: RF (ë¬´ìœ„í—˜ ì´ììœ¨)
            
        Returns:
            expected_returns: ê¸°ëŒ€ ìˆ˜ìµë¥  (batch_size, num_assets)
        """
        if common_data is None or common_data.shape[-1] < 2:
            raise ValueError("common_dataê°€ ì œê³µë˜ì§€ ì•Šì•˜ê±°ë‚˜ Mkt-RF, RF ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Fama-French ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # Fama-French ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ
        # ì „ì²´ lookback ê¸°ê°„ì˜ í‰ê· ê°’ ì‚¬ìš© 
        market_premium = common_data[:, :, 0].mean(dim=1)  # Mkt-RF (batch_size,)
        risk_free_rate = common_data[:, :, 1].mean(dim=1)  # RF (batch_size,)
        
        # ì°¨ì› ë§ì¶”ê¸°
        if market_premium.dim() == 1:
            market_premium = market_premium.unsqueeze(-1)  # (batch_size, 1)
        if risk_free_rate.dim() == 1:
            risk_free_rate = risk_free_rate.unsqueeze(-1)  # (batch_size, 1)
            
        # CAPM: E(R_i) = R_f + Î²_i * (E(R_m) - R_f)
        # ì—¬ê¸°ì„œ market_premium = E(R_m) - R_f ì´ë¯€ë¡œ
        expected_returns = risk_free_rate + betas * market_premium
        return expected_returns
    
    def compute_covariance_matrix(self, returns_data):
        """
        ìˆ˜ìµë¥  ë°ì´í„°ì—ì„œ í‘œë³¸ ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
        
        Args:
            returns_data: ê³¼ê±° ìˆ˜ìµë¥  (batch_size, time_steps, num_assets)
            
        Returns:
            cov_matrix: ê³µë¶„ì‚° í–‰ë ¬ (batch_size, num_assets, num_assets)
        """
        batch_size, time_steps, num_assets = returns_data.shape
        
        # ë°ì´í„° ì¤‘ì‹¬í™” (í‰ê·  ì°¨ê°)
        mean_returns = returns_data.mean(dim=1, keepdim=True)  # (batch, 1, assets)
        centered_returns = returns_data - mean_returns  # (batch, time, assets)
        
        # ê³µë¶„ì‚° ê³„ì‚°: (1/(T-1)) * X^T * X
        cov_matrix = torch.bmm(
            centered_returns.transpose(1, 2),  # (batch, assets, time)
            centered_returns  # (batch, time, assets)
        ) / (time_steps - 1)  # (batch, assets, assets)
        
        # ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•œ ì •ê·œí™” ì¶”ê°€
        eye = torch.eye(num_assets, device=cov_matrix.device)
        cov_matrix = cov_matrix + self.cov_regularization * eye
        
        return cov_matrix
    
    def mean_variance_optimization(self, expected_returns, cov_matrix):
        """
        ìˆ˜ì¹˜ì ìœ¼ë¡œ ì•ˆì •í•œ í‰ê· -ë¶„ì‚° ìµœì í™” í•´ê²°
        
        Args:
            expected_returns: ê¸°ëŒ€ ìˆ˜ìµë¥  (batch_size, num_assets)
            cov_matrix: ê³µë¶„ì‚° í–‰ë ¬ (batch_size, num_assets, num_assets)
            
        Returns:
            weights: í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ (batch_size, num_assets), í•©ê³„ = 1
        """
        batch_size = expected_returns.shape[0]
        device = expected_returns.device
        
        # ì…ë ¥ ê²€ì¦ ë° ì •ê·œí™”
        expected_returns = torch.clamp(expected_returns, min=-0.5, max=0.5)  # ê·¹í•œê°’ ì œí•œ
        
        try:
            # ë” ì•ˆì •í•œ ì—­í–‰ë ¬ ê³„ì‚°ì„ ìœ„í•´ SVD ë¶„í•´ ì‚¬ìš©
            # ë˜ëŠ” ì•ˆì •í•œ ì„ í˜• ì‹œìŠ¤í…œ í•´ê²°ì„ ìœ„í•´ solve ì‚¬ìš©
            ones = torch.ones(batch_size, self.num_assets, 1, device=device)
            
            # ì œì•½ ì¡°ê±´: w^T * 1 = 1ì„ ë§Œì¡±í•˜ëŠ” ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ê³„ì‚°
            # solve: cov_matrix * w = expected_returns
            try:
                weights = torch.linalg.solve(cov_matrix, expected_returns.unsqueeze(-1)).squeeze(-1)
            except:
                # solve ì‹¤íŒ¨ ì‹œ ë” ì•ˆì •í•œ ë°©ë²• ì‚¬ìš©
                weights = torch.linalg.lstsq(cov_matrix, expected_returns.unsqueeze(-1))[0].squeeze(-1)
            
            # ê°€ì¤‘ì¹˜ í¬ê¸° ì œí•œ (í­ë°œ ë°©ì§€)
            weights = torch.clamp(weights, min=-10.0, max=10.0)
            
            # ì •ê·œí™”: í•©ì´ 1ì´ ë˜ë„ë¡
            weights_sum = weights.sum(dim=1, keepdim=True)
            weights_sum = torch.clamp(torch.abs(weights_sum), min=1e-8)
            weights = weights / weights_sum
            
            # NaN ë˜ëŠ” Inf ì²´í¬
            if not torch.isfinite(weights).all():
                raise RuntimeError("ê°€ì¤‘ì¹˜ì— NaN ë˜ëŠ” Infê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            # ëª¨ë“  ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ ëŒ€ì²´ ë°©ë²•: ë™ì¼ ê°€ì¤‘ì¹˜
            print(f"ìµœì í™” ì‹¤íŒ¨: {e}. ë™ì¼ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            weights = torch.ones(batch_size, self.num_assets, device=device) / self.num_assets
        
        # ìµœì¢… ì•ˆì „ ê²€ì¦
        weights = torch.clamp(weights, min=0.0, max=1.0)  # ë¬¼ë¦¬ì  ì œì•½ ì¡°ê±´
        
        # ì •ê·œí™” (ë§ˆì§€ë§‰ ì•ˆì „ì¥ì¹˜)
        weights_sum = weights.sum(dim=1, keepdim=True)
        weights_sum = torch.clamp(weights_sum, min=1e-8)
        weights = weights / weights_sum
        
        return weights
    
    def validate_portfolio_weights(self, weights, tolerance=1e-6):
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì œì•½ ì¡°ê±´ ê²€ì¦
        
        Args:
            weights: í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ (batch_size, num_assets)
            tolerance: í—ˆìš© ì˜¤ì°¨
            
        Returns:
            bool: ëª¨ë“  ì œì•½ ì¡°ê±´ì´ ë§Œì¡±ë˜ë©´ True
        """
        batch_size = weights.shape[0]
        
        # 1. ê°€ì¤‘ì¹˜ í•©ì´ 1ì¸ì§€ í™•ì¸
        weights_sum = weights.sum(dim=1)  # (batch_size,)
        sum_constraint = torch.abs(weights_sum - 1.0) <= tolerance
        
        # 2. ê°€ì¤‘ì¹˜ê°€ ìœ í•œí•œ ê°’ì¸ì§€ í™•ì¸ (NaN, Inf ì²´í¬)
        finite_constraint = torch.isfinite(weights).all(dim=1)
        
        # ëª¨ë“  ë°°ì¹˜ ìƒ˜í”Œì´ ì œì•½ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
        all_valid = (sum_constraint & finite_constraint).all()
        
        if not all_valid:
            print(f"í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì œì•½ ì¡°ê±´ ìœ„ë°˜:")
            print(f"  - ê°€ì¤‘ì¹˜ í•©: {weights_sum}")
            print(f"  - í•© ì œì•½ ë§Œì¡±: {sum_constraint.sum()}/{batch_size}")
            print(f"  - ìœ í•œì„± ì œì•½ ë§Œì¡±: {finite_constraint.sum()}/{batch_size}")
            
        return all_valid.item()
    
    def calculate_sharpe_ratio(self, weights, expected_returns, cov_matrix, risk_free_rate=None):
        """
        ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°: (E(R_p) - R_f) / Ïƒ_p
        
        Args:
            weights: í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ (batch_size, num_assets)
            expected_returns: ê¸°ëŒ€ ìˆ˜ìµë¥  (batch_size, num_assets)
            cov_matrix: ê³µë¶„ì‚° í–‰ë ¬ (batch_size, num_assets, num_assets)
            risk_free_rate: ë¬´ìœ„í—˜ ì´ììœ¨ (í•„ìˆ˜)
            
        Returns:
            sharpe_ratio: ìƒ¤í”„ ë¹„ìœ¨ (batch_size,)
        """
        if risk_free_rate is None:
            raise ValueError("ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” ë¬´ìœ„í—˜ ì´ììœ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
        # í¬íŠ¸í´ë¦¬ì˜¤ ê¸°ëŒ€ ìˆ˜ìµë¥ : w^T * Î¼
        portfolio_return = torch.sum(weights * expected_returns, dim=1)  # (batch,)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì‚°: w^T * Î£ * w
        portfolio_variance = torch.bmm(
            torch.bmm(weights.unsqueeze(1), cov_matrix),  # (batch, 1, assets)
            weights.unsqueeze(-1)  # (batch, assets, 1)
        ).squeeze()  # (batch,)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ í‘œì¤€í¸ì°¨
        portfolio_std = torch.sqrt(torch.clamp(portfolio_variance, min=1e-8))
        
        # ìƒ¤í”„ ë¹„ìœ¨
        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std
        
        return sharpe_ratio
    
    def calculate_realized_sharpe_ratio(self, weights, future_returns, common_data):
        """
        ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°: ì‹¤ì œ ë¯¸ë˜ ìˆ˜ìµë¥  ë°ì´í„° ì‚¬ìš©
        
        Args:
            weights: í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ (batch_size, num_assets)
            future_returns: ë¯¸ë˜ ìˆ˜ìµë¥  (batch_size, pred_horizon, num_assets)
            common_data: ê³µí†µ ì‹œì¥ ë°ì´í„° (batch_size, seq_len, 2)
            
        Returns:
            realized_sharpe_ratio: ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ (batch_size,)
        """
        # ê° ë‚ ì§œë³„ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
        # future_returns: (batch_size, pred_horizon, num_assets)
        # weights: (batch_size, num_assets)
        daily_portfolio_returns = torch.sum(
            weights.unsqueeze(1) * future_returns, dim=2
        )  # (batch_size, pred_horizon)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  í†µê³„
        portfolio_mean = daily_portfolio_returns.mean(dim=1)  # (batch_size,)
        portfolio_std = daily_portfolio_returns.std(dim=1)    # (batch_size,)
        
        # ë¬´ìœ„í—˜ ì´ììœ¨ (ê°™ì€ ê¸°ê°„ í‰ê· )
        risk_free_rate = common_data[:, :, 1].mean(dim=1)  # (batch_size,)
        
        # ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨
        realized_sharpe = (portfolio_mean - risk_free_rate) / torch.clamp(portfolio_std, min=1e-8)
        
        return realized_sharpe

    def forward(self, asset_data, common_data, future_returns):
        """
        ì ì‘í˜• í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”ê¸°ì˜ ì „ì²´ ìˆœì „íŒŒ í•¨ìˆ˜
        
        Args:
            asset_data: ìì‚° ìˆ˜ìµë¥  í…ì„œ
                - ë°°ì¹˜ ì²˜ë¦¬ ì‹œ: (batch_size, num_assets, seq_len, 1)
                - ë‹¨ì¼ ìƒ˜í”Œ: (num_assets, seq_len, 1)
            common_data: ê³µí†µ ì‹œì¥ ë°ì´í„°
                - ë°°ì¹˜ ì²˜ë¦¬ ì‹œ: (batch_size, seq_len, num_features)
                - ë‹¨ì¼ ìƒ˜í”Œ: (seq_len, num_features)
                - ì¸ë±ìŠ¤ 0: Mkt-RF, ì¸ë±ìŠ¤ 1: RF
            future_returns: ìƒ¤í”„ ê³„ì‚°ì„ ìœ„í•œ ë¯¸ë˜ ìˆ˜ìµë¥ 
                - ë°°ì¹˜ ì²˜ë¦¬ ì‹œ: (batch_size, pred_horizon, num_assets)
                - ë‹¨ì¼ ìƒ˜í”Œ: (pred_horizon, num_assets)
            
        Returns:
            dict: ëª¨ë“  ì¤‘ê°„ ê²°ê³¼ì™€ ìµœì¢… ì†ì‹¤ì„ í¬í•¨
        """
        # ë°ì´í„°ë¡œë”ì—ì„œ ì˜¤ëŠ” í˜•íƒœì— ë§ê²Œ ì°¨ì› ì¡°ì •
        if asset_data.dim() == 4:
            # ë°°ì¹˜ ì²˜ë¦¬: (batch_size, num_assets, seq_len, 1) -> (batch_size, num_assets, seq_len)
            asset_data = asset_data.squeeze(-1)
        elif asset_data.dim() == 3 and asset_data.shape[2] == 1:
            # ë‹¨ì¼ ìƒ˜í”Œ: (num_assets, seq_len, 1) -> (1, num_assets, seq_len)
            asset_data = asset_data.squeeze(-1).unsqueeze(0)
        
        if common_data.dim() == 2:
            # ë‹¨ì¼ ìƒ˜í”Œ: (seq_len, num_features) -> (1, seq_len, num_features)
            common_data = common_data.unsqueeze(0)
        # ë°°ì¹˜ ì²˜ë¦¬ì¸ ê²½ìš° (batch_size, seq_len, num_features)ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
            
        # future_returns ì°¨ì› ì²˜ë¦¬ (ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ì„ ìœ„í•´ ì›ë³¸ ë³´ì¡´)
        original_future_returns = future_returns.clone()
        
        if future_returns.dim() == 2:
            # ë‹¨ì¼ ìƒ˜í”Œ: (pred_horizon, num_assets) -> (1, pred_horizon, num_assets)
            original_future_returns = future_returns.unsqueeze(0)
            # í‰ê·  ê³„ì‚°: -> (1, num_assets)
            future_returns = future_returns.mean(dim=0).unsqueeze(0)
        elif future_returns.dim() == 3:
            # ë°°ì¹˜ ì²˜ë¦¬: (batch_size, pred_horizon, num_assets) -> (batch_size, num_assets) (í‰ê·  ì‚¬ìš©)
            future_returns = future_returns.mean(dim=1)
            
        batch_size = asset_data.shape[0]
        
        # ë‹¨ê³„ 1: TCNì„ ì‚¬ìš©í•œ ë² íƒ€ ì¶”ì •
        betas = self.beta_estimator(asset_data, common_data)
        
        # ë‹¨ê³„ 2: CAPMì„ ì‚¬ìš©í•œ ê¸°ëŒ€ ìˆ˜ìµë¥  ê³„ì‚° (common_dataì—ì„œ ì§ì ‘ ì¶”ì¶œ)
        expected_returns = self.capm_expected_returns(betas, None, common_data=common_data)
        
        # ë‹¨ê³„ 3: ê³¼ê±° ë°ì´í„°ì—ì„œ ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
        # ê³µë¶„ì‚° ê³„ì‚°ì„ ìœ„í•œ asset_data ì¬êµ¬ì„±: (batch, assets, seq) -> (batch, seq, assets)
        returns_for_cov = asset_data.transpose(1, 2)
        cov_matrix = self.compute_covariance_matrix(returns_for_cov)
        
        # ë‹¨ê³„ 4: í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ í‰ê· -ë¶„ì‚° ìµœì í™”
        weights = self.mean_variance_optimization(expected_returns, cov_matrix)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì œì•½ ì¡°ê±´ ê²€ì¦ (ë””ë²„ê¹…ìš©)
        if not self.validate_portfolio_weights(weights):
            print("ê²½ê³ : í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ ì œì•½ ì¡°ê±´ì´ ìœ„ë°˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë‹¨ê³„ 5: ë¯¸ë˜ ìˆ˜ìµë¥ ì„ ì‚¬ìš©í•œ ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
        # í›ˆë ¨ì„ ìœ„í•´ future_returnsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í˜„ëœ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
        realized_portfolio_return = torch.sum(weights * future_returns, dim=1)
        
        # ë¦¬ìŠ¤í¬ ì¶”ì •ì„ ìœ„í•´ ê³¼ê±° ê³µë¶„ì‚° ì‚¬ìš© (ë” ì•ˆì •ì )
        # ì´ë¡ ì  ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°ì—ì„œë„ ì‹¤ì œ RF ê°’ ì‚¬ìš©
        current_rf = common_data[:, :, 1].mean(dim=1)  # ì „ì²´ ê¸°ê°„ í‰ê·  RF
        theoretical_sharpe_ratio = self.calculate_sharpe_ratio(weights, expected_returns, cov_matrix, risk_free_rate=current_rf)
        
        # ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° (ì‹¤ì œ ë¯¸ë˜ ìˆ˜ìµë¥  ì‚¬ìš©)
        realized_sharpe_ratio = self.calculate_realized_sharpe_ratio(weights, original_future_returns, common_data)
        
        # ë‹¨ê³„ 6: ì†ì‹¤ = -ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ (ì‹¤ì œ íˆ¬ì ì„±ê³¼ ê¸°ë°˜ í•™ìŠµ)
        # ë°°ì¹˜ ë‚´ ìƒ˜í”Œë“¤ì˜ ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨ í‰ê· ì„ ìµœëŒ€í™”
        loss = -realized_sharpe_ratio.mean()
        
        return {
            'betas': betas,
            'expected_returns': expected_returns,
            'weights': weights,
            'cov_matrix': cov_matrix,
            'sharpe_ratio': theoretical_sharpe_ratio,  # ì´ë¡ ì  ìƒ¤í”„ ë¹„ìœ¨
            'realized_sharpe_ratio': realized_sharpe_ratio,  # ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨
            'realized_return': realized_portfolio_return,
            'loss': loss
        }

